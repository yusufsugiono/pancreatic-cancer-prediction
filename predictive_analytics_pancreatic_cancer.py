# -*- coding: utf-8 -*-
"""Predictive Analytics - Pancreatic Cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QNEY5MYuvhZMNQ5I_aia8sYuC5fnkAvu

# **Predictive Analytics** : Diagnosa Kanker Pankreas Berdasarkan Biomarker Urin
---
Oleh : [Yusuf Sugiono](https://dicoding.com/users/yusufsugiono)

![Infographics: Pancreatic Cancer, medindia.net](https://www.medindia.net/images/common/infographics/article-images/950_400/pancreatic-cancer-infographic.jpg)

## Pendahuluan

- Latar Belakang  
Kanker pankreas adalah jenis kanker yang sangat mematikan. Setelah didiagnosis, tingkat kelangsungan hidup lima tahun kurang dari 10%. Namun, jika kanker pankreas terdeteksi lebih awal, kemungkinan bertahan hidup jauh lebih baik. Sayangnya, banyak kasus kanker pankreas tidak menunjukkan gejala hingga kanker menyebar ke seluruh tubuh. Tes diagnostik untuk mengidentifikasi orang dengan kanker pankreas bisa sangat membantu.

## Penyiapan Data

### Mengimpor Library
"""

# Import Library
from google.colab import files
import os
import zipfile
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

"""### Menyiapkan Kredensial Kaggle

Dataset yang akan dipakai dalam proyek ini diambil dari platform Kaggle. Maka dari itu, sebelum dapat mengunduh data, harus mengunggah kredensial berupa file JSON yang dapat di-generate melalui profil akun Kaggle. 
"""

# Upload kaggle.json
uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}"'.format(
      name=fn))

# Ubah permission file
!chmod 600 /content/kaggle.json

# Setup Kaggle environment
os.environ['KAGGLE_CONFIG_DIR'] = "/content"

"""### Mengunduh Dataset

![Urinary biomarkers for pancreatic cancer dataset](https://i.postimg.cc/G2T1WCB3/Screenshot-6.png)

Informasi Dataset:

Jenis | Keterangan
--- | ---
Title | Urinary biomarkers for pancreatic cancer
Source | [Kaggle](https://www.kaggle.com/johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer)
Maintainer | [John Davis](https://www.kaggle.com/johnjdavisiv)
License | Data files Â© Original Authors
Visibility | Public
Tags | biology, cancer, health conditions, beginner, binary classification, medicine
Usability | 10.0
"""

# Download dataset
!kaggle datasets download -d johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer

# melakukan ekstraksi pada file zip
local_zip = 'urinary-biomarkers-for-pancreatic-cancer.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/urinary-biomarkers-for-pancreatic-cancer/')
zip_ref.close()

# Menghapus berkas zip yang sudah tidak diperlukan
!rm urinary-biomarkers-for-pancreatic-cancer.zip

"""## Data Understanding

Langkah pertama untuk memahami data yaitu dengan melihat isi dari direktori dataset yang telah diunduh
"""

# Cek isi direktori dataset
os.listdir('/content/urinary-biomarkers-for-pancreatic-cancer')

"""Dari keluaran di atas, dapat diketahui bahwa ada dua berkas data, diantaranya adalah dataset utama dan berkas lainnya adalah merupakan dokumentasi.

Mari kita lihat data dokumentasinya dengan menggunakan `pandas`
"""

# Cek dokumentasi dataset
data_docs = pd.read_csv('/content/urinary-biomarkers-for-pancreatic-cancer/Debernardi et al 2020 documentation.csv')
data_docs

"""Dari keluaran di atas, menunjukkan bahwa dokumentasi ini berisi fitur yang ada pada dataset beserta penjelasannya. Namun string yang terlalu panjang terpotong dan tidak dapat dibaca dengan baik. Untuk itu perlu menyesuaikan lebar kolom terlebih dahulu untuk memunculkan semua teksnya."""

# Cek ukuran lebar kolom
pd.options.display.max_colwidth

# Memperlebar ukuran kolom
pd.options.display.max_colwidth = 500

data_docs

"""Dari dataframe di atas kita dapat melihat bahwa pada dataset ini terdapat 14 kolom. Diantaranya:

1. `sample_id` : merupakan string unik yang mengidentifikasi setiap subjek
2. `patient_cohort` : menyatakan kelompok pasien, memiliki 2 nilai, yaitu *Cohort 1*, sampel yang sebelumnya digunakan; *Cohort 2*, sampel yang baru ditambahkan
3. `sample_origin` : menyatakan sumber sampel data
4. `age` : menyatakan usia pasien dalam tahun
5. `sex` : menyatakan jenis kelamin pasien (M=Pria, F=Wanita)
6. `diagnosis` : menyatakan diagnosis (1=sehat, 2=benign hepatobiliary disease/bukan kanker, 3=kanker pankreas)
7. `stage` : menyatakan tingkat kanker pankreas yang diderita pasien (IA, IB, IIA, IIIB, III, IV)
8. `benign_sample_diagnosis` : diagnosis untuk mereka penderita benign hepatobiliary disease / non-kanker
9. `plasma_CA19_9` : Kadar plasma darah dari antibodi monoklonal CA 19-9 yang sering meningkat pada pasien dengan kanker pankreas. 
10. `creatinine	` : Biomarker urin dari fungsi ginjal
11. `LYVE1` : Tingkat urin reseptor *Lymphatic vessel endothelial hyaluronan* 1, protein yang mungkin berperan dalam metastasis tumor
12. `REG1B` : Kadar protein urin yang mungkin terkait dengan regenerasi pankreas
13. `TFF1` : Tingkat urin *Trefoil Factor* 1, yang mungkin terkait dengan regenerasi dan perbaikan saluran kemih.
14. `REG1A` : Kadar protein urin yang mungkin berhubungan dengan regenerasi pankreas.

Kita dapat melihat isi dari datasetnya menggunakan pandas sebagai berikut.
"""

# Memuat dataset
df = pd.read_csv('/content/urinary-biomarkers-for-pancreatic-cancer/Debernardi et al 2020 data.csv')
df

"""Dari keluaran di atas dapat diketahui bahwa dataset yang akan digunakan memiliki 590 sampel atau baris data dengan 14 kolom."""

df.info()

"""Dari eksekusi method `info()` dapat diketahui bahwa terdapat banyak *missing value* di beberapa kolom, diantaranya pada `stage`, `benign_sample_diagnosis`, `plasma_CA19_9`, dan `REG1A`"""

df.describe()

"""## Data Preparation

### Menghapus Fitur yang Tidak Perlu

Pada proyek ini berfokus pada diagnosa apakah pasien menderita kanker pankreas atau tidak. Untuk itu beberapa kolom yang dirasa kurang diperlukan dapat di-drop.
"""

# Menghapus kolom yang tidak diperlukan
df = df.drop(columns=['sample_id','patient_cohort','sample_origin','stage','benign_sample_diagnosis'])
df.head()

"""### Penanganan Missing Value

Seperti yang telah diketahui sebelumnya pada tahap Data Understanding, dataset ini memiliki beberapa kolom dengan missing value. Jumlah missing value-nya pun cukup banyak sehingga tidak dapat di-drop begitu saja. Untuk itu perlu penanganan berupa mengisinya dengan nilai rata-rata atau mean.
"""

# Handling missing value dengan nilai rata-rata
for i in df[:]:
    if i!='sex':
        df[i] = df[i].fillna(df[i].mean())
df.head()

df.info()

"""### Menangani Nilai Diagnosa

Pada kolom diagnosis, terdapat 3 jenis nilai diantaranya adalah 1 (untuk pankreas yang sehat), 2 (untuk penderita benign hepatobiliary disease dan bukan merupakan kanker), 3 (untuk penderita kanker pankreas). Untuk itu pada proyek ini nilainya akan diubah dan hanya akan digolongkan ke 2 nilai yaitu 0 (untuk bukan penderita kanker pankreas) dan 1 (untuk penderita kanker pankreas).
"""

# Mengubah nilai diagnosis menjadi 0 dan 1
df['diagnosis'].replace([1,2,3], [0,0,1], inplace=True)

df.head()

"""### One Hot Encoding

One Hot Encoding merupakan teknik untuk merepresentasikan variabel atau fitur kategorikan ke dalam vektor biner.
"""

# Melakukan OneHotEncoding pada data sex
df = pd.get_dummies(df)
df.head()

"""### Menangani Pencilan (Outliers)

Outliers adalah titik data yang berbeda secara signifikan dari pengamatan lainnya sehingga dapat berakibat buruk pada model prediksi. Pada proyek ini menggunakan IQR *(InterQuartile Range)* untuk mendeteksi outliers. IQR dapat menentukan data outliers yang kondisinya di luar batas bawah atau batas atas dari dataset. IQR dapat divisualkan menggunakan `boxplot`.
"""

sns.boxplot(x=df['age'])

sns.boxplot(x=df['plasma_CA19_9'])

sns.boxplot(x=df['creatinine'])

sns.boxplot(x=df['LYVE1'])

sns.boxplot(x=df['REG1B'])

sns.boxplot(x=df['TFF1'])

sns.boxplot(x=df['REG1A'])

# Menghapus outliers yang ada pada dataset
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR=Q3-Q1
new_df = df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]
 
# ukuran dataset setelah drop outliers
new_df.shape

"""### Split Dataset

Pembagian dataset ini bertujuan agar nantinya dapat digunakan untuk melatih dan mengevaluasi kinerja model. Pada proyek ini, 80% dataset digunakan untuk melatih model, dan 20% sisanya digunakan untuk mengevaluasi model.
"""

# Menentukan fitur (X) dan label (y)
X = new_df.drop(["diagnosis"],axis =1)
y = new_df["diagnosis"]

# Split dataset menjadi data latih dan data uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 60)

# Jumlah data terkini
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Normalisasi

Pada proyek ini akan menggunakan MinMaxScaler, yaitu teknik normalisasi yang mentransformasikan nilai fitur atau variabel ke dalam rentang [0,1] yang berarti bahwa nilai minimum dan maksimum dari fitur/variabel masing-masing adalah 0 dan 1
"""

# Normalisasi dengan MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""## Modeling

Pada tahap ini akan dibuat beberapa model diantaranya menggunakan K-Nearest Neighbor, Random Forest, Support Vector Machine Classifier, dan Naive Bayes.
"""

# Menyiapkan dataframe untuk analisis model
models = pd.DataFrame(index=['accuracy_score'], 
                      columns=['KNN', 'RandomForest', 'SVM', 'Naive Bayes'])

"""### KNN (K-Nearest Neighbor)"""

# Buat model prediksi dengan KNN
model_knn = KNeighborsClassifier(n_neighbors=3)
model_knn.fit(X_train, y_train)

# Lakukan prediksi dengan model KNN
knn_pred = model_knn.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','KNN'] = accuracy_score(y_test, knn_pred)

"""### Random Forest"""

# Buat model prediksi dengan Random Forest
model_rf = RandomForestClassifier()
model_rf.fit(X_train, y_train)

# Lakukan prediksi dengan model Random Forest
rf_pred = model_rf.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','RandomForest'] = accuracy_score(y_test, rf_pred)

"""### Support Vector Classifier"""

# Buat model prediksi dengan Support Vector Machine Classifier
model_svc = SVC()
model_svc.fit(X_train, y_train)

# Lakukan prediksi dengan model SVM Classifier
svc_pred = model_svc.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','SVM'] = accuracy_score(y_test, svc_pred)

"""### Naive Bayes"""

# Buat model prediksi dengan Bernoulli Naive Bayes
model_nb = BernoulliNB()
model_nb.fit(X_train, y_train)

# Lakukan prediksi dengan model Naive Bayes
nb_pred = model_nb.predict(X_test)

# Hitung metriks akurasi dan simpan hasilnya
models.loc['accuracy_score','Naive Bayes'] = accuracy_score(y_test, nb_pred)

"""## Evaluation

Setelah mendapatkan beberapa model, maka dapat dibandingkan akurasi prediksinya untuk mendapatkan model dengan kinerja yang terbaik. Agar lebih mudah dapat menggunakan visualisasi seperti berikut.
"""

# Menampilkan perbandingan akurasi beberapa model yang telah dibuat
plt.bar('KNN', models['KNN'])
plt.bar('RandomForest', models['RandomForest'])
plt.bar('SVM', models['SVM'])
plt.bar('Naive Bayes', models['Naive Bayes'])
plt.title("Perbandingan Akurasi Model");
plt.xlabel('Model');
plt.ylabel('Akurasi');
plt.show()

"""Dari diagram batang di atas dapat diketahui bahwa model dengan Random Forest memiliki akurasi yang paling tinggi dibanding 3 model lainnya. Untuk itu, model inilah yang akan dipilih dan dipakai.

## Penutup
Saat ini model untuk memprediksi kanker pankreas telah didapatkan. Dengan model ini dapat diimplementasikan lebih lanjut menjadi aplikasi yang siap digunakan. Namun tentu saja model ini juga masih dapat disempurnakan dengan mencoba algoritma yang lain, melakukan fine-tuning, atau dengan mengubah dataset yang lebih beragam dan berkualitas.
"""